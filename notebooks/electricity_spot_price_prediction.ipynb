{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading modules automatically when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "## Little Hack to import the utils module to the notebook\n",
    "##################################################################\n",
    "# Add the parent directory to the path so we can import the utils\n",
    "original_sys_path = sys.path.copy()\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "from src.utils import *\n",
    "sys.path = original_sys_path # Reset the path to the original\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = '../data/spot_prices_fi_2016_2023.csv'\n",
    "\n",
    "# Define dict where predictions and metrices are stored\n",
    "predictions = {}\n",
    "metrices = {}\n",
    "horizon = 24\n",
    "\n",
    "# Preprocess the data\n",
    "processed_data = preprocess_data(file_path, date_col=\"date\", price_col=\"elspot-fi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the preprocessed data\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove first two rows as it is only one row for 2015 (because of the UTC conversion in data preprocessing)\n",
    "processed_data = processed_data.iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=processed_data.index, y=processed_data.y, mode='lines', name='Spot Price'))\n",
    "# add zoom\n",
    "fig.update_layout(xaxis_rangeslider_visible=True)\n",
    "fig.update_layout(title='Spot Price Over Time', xaxis_title='Time', yaxis_title='Spot Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processed_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1. Simple Baseline Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na = NaiveModel()\n",
    "\n",
    "# year on year training\n",
    "result_na, na_metrics = year_on_year_training(df, na, refit=True)\n",
    "predictions['Naive'] = [{'predictions': result_na}]\n",
    "metrices['Naive'] = na_metrics\n",
    "print(na_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "plot_spot_price_predictions(df['y'], result_na, 'Naive Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha = HistoricalAverageModel()\n",
    "\n",
    "# year on year training\n",
    "result_ha, ha_metrics = year_on_year_training(df, ha, refit=True)\n",
    "predictions['Historical Average'] = [{'predictions': result_ha}]\n",
    "metrices['Historical Average'] = ha_metrics\n",
    "print(ha_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "plot_spot_price_predictions(df['y'], result_ha, 'Historical Average Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a WindowAverageModel instance with a window size of 24 hours\n",
    "wa = WindowAverageModel(window_size=horizon)\n",
    "wa_predictions, wa_metrics = year_on_year_training(df, wa, refit=True)\n",
    "predictions['Window Average'] = [{'predictions': wa_predictions}]\n",
    "metrices['Window Average'] = wa_metrics\n",
    "print(wa_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "plot_spot_price_predictions(df['y'], wa_predictions, 'Window Average Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea = ExponentialAverage(alpha=0.2)\n",
    "ea_predictions, ea_metrics = year_on_year_training(df, ea, refit=True)\n",
    "predictions['Exponential Average'] = [{'predictions': ea_predictions}]\n",
    "metrices['Exponential Average'] = ea_metrics\n",
    "print(ea_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "plot_spot_price_predictions(df['y'], ea_predictions, 'Exponential Average Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2. Linear Regression with Time Component**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = extract_time_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "lr_time_features = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# year on year training\n",
    "lr_time_predictions, lr_time_metrics, lr_time_features_coeffs = year_on_year_training(df_time, lr_time_features)\n",
    "predictions['LR (Time Component)'] = [{'predictions' :lr_time_predictions}]\n",
    "metrices['LR (Time Component)'] = lr_time_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_time_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_year_over_year_coefficients(lr_time_features_coeffs, keyword=\"weekday\", model_name='LR (Time Component)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_year_over_year_coefficients(lr_time_features_coeffs, keyword=\"weekend\", model_name='LR (Time Component)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3. Download External Features from Fingrid**\n",
    "\n",
    "Note: Uncomment the code to download the external features from Fingrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the available data types\n",
    "# datasets = fetch_data(\"datasets\", params = {'pageSize': 20000, 'orderBy': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the dataset infrormation and descriptions\n",
    "# for dataset in datasets:\n",
    "#     print(f\"{dataset['id']} - {dataset['nameEn']} ({dataset['dataPeriodEn']})\")\n",
    "#     print(\"Description:\", dataset['descriptionEn'])\n",
    "#     print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download datasets by id\n",
    "# start_time = df.index[0].strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "# end_time = df.index[-1].strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "# dataset_ids = ['247']\n",
    "# for dataset_id in dataset_ids:\n",
    "#     # check if dataset is already downloaded\n",
    "#     if os.path.exists(f'../data/{dataset_id}.csv'):\n",
    "#         print(f'Dataset {dataset_id} already downloaded.')\n",
    "#         print(\"-\"*20)\n",
    "#         continue\n",
    "#     try:\n",
    "#         data = fetch_data(\"data\", params = {'datasets': dataset_id, 'startTime': start_time, 'endTime': end_time, 'format': 'json', 'oneRowPerTimePeriod': 'true', 'pageSize': 20000, 'locale': 'en', 'sortBy': 'startTime', 'sortOrder': 'asc'})\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching dataset {dataset_id}: {e}\")\n",
    "#         print(\"-\"*20)\n",
    "#         continue\n",
    "\n",
    "#     # convert data to dataframe\n",
    "#     data = pd.DataFrame(data)\n",
    "#     data['startTime'] = pd.to_datetime(data['startTime'])\n",
    "#     data.set_index('startTime', inplace=True)\n",
    "#     # drop endTime\n",
    "#     data.drop(columns='endTime', inplace=True)\n",
    "#     data.sort_index(inplace=True)\n",
    "#     # localize index to none\n",
    "#     data.index = data.index.tz_localize(None)\n",
    "#     print(f'Dataset {dataset_id} length:', len(data))\n",
    "#     print(\"-\"*20)\n",
    "#     data.to_csv(f'../data/{dataset_id}.csv')\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.4. Time + External Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_add = ['246', '247', '165', '242'] # ids of the previously downloaded dataset\n",
    "len_ext_features = len(features_to_add) \n",
    "df_ext_features = add_external_features(df_time, features_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column name\n",
    "df_ext_features.rename(\n",
    "    {'Electricity production prediction - premilinary': 'electricity_production_forecast',\n",
    "     'Electricity consumption forecast - next 24 hours': 'electricity_consumption_forecast',\n",
    "     'Solar power generation forecast - updated once a day': 'solar_power_generation_forecast',\n",
    "     'Wind power generation forecast - updated once a day': 'wind_power_generation_forecast'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot external variables\n",
    "fig = go.Figure()\n",
    "for col in df_ext_features.columns[-len_ext_features:]:\n",
    "    fig.add_trace(go.Scatter(x=df_ext_features.index, y=df_ext_features[col], mode='lines', name=col))\n",
    "# add zoom\n",
    "fig.update_layout(xaxis_rangeslider_visible=True)\n",
    "fig.update_layout(title='External Features Over Time', xaxis_title='Time', yaxis_title='Feature Value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with given fill functions\n",
    "missing_mapping = {\n",
    "    'electricity_consumption_forecast': ['ffill','bfill'],\n",
    "    'electricity_production_forecast': ['ffill','bfill'],\n",
    "    'wind_power_generation_forecast': ['ffill','bfill'],\n",
    "    'solar_power_generation_forecast': ['interpolate','bfill','ffill'],\n",
    "}\n",
    "\n",
    "df_ext_features = fill_missing_values(df_ext_features, missing_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot external variables\n",
    "fig = go.Figure()\n",
    "for col in df_ext_features.columns[-len_ext_features:]:\n",
    "    fig.add_trace(go.Scatter(x=df_ext_features.index, y=df_ext_features[col], mode='lines', name=col))\n",
    "# add zoom\n",
    "fig.update_layout(xaxis_rangeslider_visible=True)\n",
    "fig.update_layout(title='External Features Over Time', xaxis_title='Time', yaxis_title='Feature Value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values\n",
    "print(df_ext_features.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "lr_ext = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# year on year training\n",
    "lr_ext_predictions, lr_ext_metrics, lr_ext_features_coeffs = year_on_year_training(df_ext_features, lr_ext)\n",
    "predictions['LR (Time + External Features)'] = [{'predictions' :lr_ext_predictions}]\n",
    "metrices['LR (Time + External Features)'] = lr_ext_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_ext_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)\n",
    "plot_year_over_year_coefficients(lr_ext_features_coeffs, keyword=\"weekday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weekend coefficients\n",
    "plot_year_over_year_coefficients(lr_ext_features_coeffs, keyword=\"weekend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot electricity production forecast\n",
    "plot_year_over_year_coefficients(lr_ext_features_coeffs, keyword=\"electricity_production_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot electricity consumption forecast\n",
    "plot_year_over_year_coefficients(lr_ext_features_coeffs, keyword=\"electricity_consumption_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wind power generation forecast\n",
    "plot_year_over_year_coefficients(lr_ext_features_coeffs, keyword=\"wind_power_generation_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot solar power generation forecast\n",
    "plot_year_over_year_coefficients(lr_ext_features_coeffs, keyword=\"solar_power_generation_forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.5. With LEAR Features**\n",
    "\n",
    "[LEAR Paper](https://www.sciencedirect.com/science/article/pii/S0306261921004529?via%3Dihub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.5.1. Time + Price Lags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lags for historical prices and forecasts\n",
    "price_lags = [1, 2, 3, 7]\n",
    "\n",
    "# Creating lag features for day-ahead prices\n",
    "df_lear_price = create_daily_lag_features(df_time, 'y', price_lags, average=True)\n",
    "\n",
    "df_lear_price = df_lear_price.copy() # avoiding fragmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lear_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the number of features\n",
    "print(f'Total number of features: {len(df_lear_price.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_lear_price.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lear_price.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lear_price = LinearRegression(fit_intercept=False)\n",
    "lear_price_predictions, lear_price_metrics, lear_price_coeffs = year_on_year_training(df_lear_price, lear_price)\n",
    "predictions['LR (Time + Price Lags)'] = [{'predictions': lear_price_predictions}]\n",
    "metrices['LR (Time + Price Lags)'] = lear_price_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lear_price_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"y_lag\", \"electricity_production\", \"electricity_consumption\", \"wind_power\", \"solar_power\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"weekday\", \"weekend\", \"y_lag\"]\n",
    "\n",
    "for col in col_names:\n",
    "    plot_year_over_year_coefficients(lear_price_coeffs, keyword=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.5.2. Time + Price Lags + External Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external features ids \n",
    "features_to_add = ['246', '247', '165', '242'] # ids of the previously downloaded dataset\n",
    "\n",
    "# add external features\n",
    "df_lear_price_ext = add_external_features(df_lear_price, features_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lear_price_ext.rename(\n",
    "    {'Electricity production prediction - premilinary': 'electricity_production_forecast',\n",
    "     'Electricity consumption forecast - next 24 hours': 'electricity_consumption_forecast',\n",
    "     'Solar power generation forecast - updated once a day': 'solar_power_generation_forecast',\n",
    "     'Wind power generation forecast - updated once a day': 'wind_power_generation_forecast'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values mapping\n",
    "missing_mapping = {\n",
    "    'electricity_consumption_forecast': ['ffill','bfill'],\n",
    "    'electricity_production_forecast': ['ffill','bfill'],\n",
    "    'wind_power_generation_forecast': ['ffill','bfill'],\n",
    "    'solar_power_generation_forecast': ['interpolate','bfill','ffill'],\n",
    "}\n",
    "\n",
    "# fill missing values\n",
    "df_lear_price_ext = fill_missing_values(df_lear_price_ext, missing_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "lear_price_ext = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# year on year training\n",
    "lear_price_ext_predictions, lear_price_ext_metrics, lear_price_ext_features_coeffs = year_on_year_training(df_lear_price_ext, lear_price_ext)\n",
    "predictions['LR (Time + Price Lags + External Features)'] = [{'predictions': lear_price_ext_predictions}]\n",
    "metrices['LR (Time + Price Lags + External Features)'] = lear_price_ext_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lear_price_ext_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"weekend\", \"weekday\", 'y_lag', 'electricity_production_forecast', 'electricity_consumption_forecast', 'wind_power_generation_forecast', 'solar_power_generation_forecast']\n",
    "\n",
    "for col in cols:\n",
    "    plot_year_over_year_coefficients(lear_price_ext_features_coeffs, keyword=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.5.3. Time + Price Lags + External Features + External Lags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast lags\n",
    "forecast_lags = [1, 7]\n",
    "\n",
    "# Creating lag features for electricity production forecast\n",
    "df_lear_price_ext_extlags = create_daily_lag_features(df_lear_price_ext, 'electricity_production_forecast', forecast_lags, average=True)\n",
    "\n",
    "# Creating lag features for electricity consumption forecast\n",
    "df_lear_price_ext_extlags = create_daily_lag_features(df_lear_price_ext_extlags, 'electricity_consumption_forecast', forecast_lags, average=True)\n",
    "\n",
    "# Creating lag features for wind power generation forecast\n",
    "df_lear_price_ext_extlags = create_daily_lag_features(df_lear_price_ext_extlags, 'wind_power_generation_forecast', forecast_lags, average=True)\n",
    "\n",
    "# Creating lag features for solar power generation forecast\n",
    "df_lear_price_ext_extlags = create_daily_lag_features(df_lear_price_ext_extlags, 'solar_power_generation_forecast', forecast_lags, average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the columns\n",
    "print(df_lear_price_ext_extlags.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "df_lear_price_ext_extlags.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "lear_price_ext_extlags = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# year on year training\n",
    "lear_price_ext_extlags_predictions, lear_price_ext_extlags_metrics, lear_price_ext_extlags_features_coeffs = year_on_year_training(df_lear_price_ext_extlags, lear_price_ext_extlags)\n",
    "predictions['LR (Time + Price Lags + External Features + External Lags)'] = [{'predictions': lear_price_ext_extlags_predictions}]\n",
    "metrices['LR (Time + Price Lags + External Features + External Lags)'] = lear_price_ext_extlags_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lear_price_ext_extlags_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot coefficients\n",
    "cols = [\"weekend\", \"weekday\", 'y_lag', 'electricity_production_forecast', 'electricity_consumption_forecast', 'wind_power_generation_forecast', 'solar_power_generation_forecast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1. Visualization of Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions, df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mae(predictions, df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print mae for each model sorted by mean_squared_error\n",
    "for key, value in sorted(metrices.items(), key=lambda x: x[1]['mean_squared_error']):\n",
    "    print(f'{key}: {value[\"mean_squared_error\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = visualize_predictions(processed_data, predictions)\n",
    "\n",
    "# run app and also show url\n",
    "app.run_server(debug=True, use_reloader=False, jupyter_mode=\"external\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2. Visualization of Predictions Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "actual_extremes = calculate_price_extremes(pd.DataFrame(df['y'][df.index.year != 2016], columns=['y']), price_column='y', top_k=top_k)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "for key, value in predictions.items():\n",
    "    predicted_extremes = calculate_price_extremes(pd.DataFrame(value[0]['predictions'], columns=['y']), price_column='y', top_k=top_k)\n",
    "    accuracy_dict = calculate_prediction_accuracy(actual_extremes, predicted_extremes, order=True, top_k=top_k, year_on_year=True)\n",
    "    plot_prediction_accuracy_histogram(accuracy_dict, title=f\"Accuracy of Top-k Hour Predictions [{key}]\", year_on_year=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.3 Visualize Baseline and Fluctuations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original data\n",
    "file_path = '../data/spot_prices_fi_2016_2023.csv'\n",
    "original_data = pd.read_csv(file_path, parse_dates=['date'], index_col='date')\n",
    "original_data.index = pd.to_datetime(original_data.index, utc=True).tz_convert(None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe with daily_fluctuation and baseline cols\n",
    "df1 = pd.DataFrame(columns=['daily_fluctuation', 'baseline'])\n",
    "for year, coeff in lear_price_ext_extlags_features_coeffs.items():\n",
    "    # filter out the coeffs with keyword 'lag' on it\n",
    "    lagged_coeff = coeff.filter(like='lag')\n",
    "\n",
    "    # filter coeff without keyword 'lag'\n",
    "    non_lagged_coeff = coeff[~coeff.index.str.contains('lag')]\n",
    "\n",
    "    # now multiply the df_lear_price_ext_extlags features with the lagged coeff and non_lagged coeff and get values seperately under 'daily_fluctuation' and 'baseline' cols\n",
    "    daily_fluctuation = df_lear_price_ext_extlags[df_lear_price_ext_extlags.index.year == year+1][non_lagged_coeff.index].mul(non_lagged_coeff.values).sum(axis=1)\n",
    "    baseline = df_lear_price_ext_extlags[df_lear_price_ext_extlags.index.year == year+1][lagged_coeff.index].mul(lagged_coeff.values).sum(axis=1)\n",
    "\n",
    "    # concat to df1\n",
    "    df1 = pd.concat([df1, pd.DataFrame({'daily_fluctuation': daily_fluctuation, 'baseline': baseline})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the daily_fluctuation and baseline\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=original_data.index, y=original_data['elspot-fi'], mode='lines', name='Actual', line=dict(color='green', width=2)))\n",
    "fig.add_trace(go.Scatter(x=df1.index, y=df1['daily_fluctuation'], mode='lines', name='Daily Fluctuation', line=dict(color='red', width=2)))\n",
    "fig.add_trace(go.Scatter(x=df1.index, y=df1['baseline'], mode='lines', name='Baseline', line=dict(color='blue', width=2)))\n",
    "fig.add_trace(go.Scatter(x=df1.index, y=df1['baseline']+df1['daily_fluctuation'], mode='lines', name='Prediction', line=dict(color='black', width=2)))\n",
    "# add predictions from exponential average\n",
    "# fig.add_trace(go.Scatter(x=ea_predictions.index, y=ea_predictions.values, mode='lines', name='Exponential Average', line=dict(color='brown', width=2)))\n",
    "fig.update_layout(title='Daily Fluctuation, Baseline, Actual Data', xaxis_title='Time', yaxis_title='Value')\n",
    "# add range slider\n",
    "# fig.update_layout(xaxis_rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the sum of y_lag_ and hourly coeffs for each year\n",
    "for year, coeffs in lear_price_ext_extlags_features_coeffs.items():\n",
    "    # print the sum of y_lag_ coeffs and hourly coeffs\n",
    "    print(f'Year {year}:')\n",
    "    print('Lag coeffs sum:', coeffs.filter(like='y_lag_').sum().round(5))\n",
    "    print('Hourly coeffs sum:' ,coeffs.filter(like='hour').sum().round(5))\n",
    "    print('-'*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.4. Export Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge daily_fluctuation and baseline with original data, if the index does not match, insert nan\n",
    "original_data = original_data.merge(df1, left_index=True, right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.to_csv('../data/predictions_2016_2023(time+external+price_lags+external_lags).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-series-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
